{
  "callbacks": "<function gen_trainer_from_params.<locals>.<lambda> at 0x7f874c3e0200>",
  "clip_param": 0.05,
  "custom_eval_function": "<function get_rllib_eval_function.<locals>._evaluate at 0x7f874c3e09e0>",
  "eager_tracing": false,
  "entropy_coeff_schedule": [
    [
      0,
      0.0
    ],
    [
      300000.0,
      0.0
    ]
  ],
  "env_config": {
    "env_params": {
      "horizon": 400,
      "mlam_params": {
        "counter_drop": [],
        "counter_goals": [],
        "counter_pickup": [],
        "same_motion_goals": true,
        "start_orientations": false,
        "wait_allowed": false
      }
    },
    "eval_mdp_params": {
      "layout_name": "cramped_room",
      "rew_shaping_params": {
        "DISH_DISP_DISTANCE_REW": 0,
        "DISH_PICKUP_REWARD": 3,
        "PLACEMENT_IN_POT_REW": 3,
        "POT_DISTANCE_REW": 0,
        "SOUP_DISTANCE_REW": 0,
        "SOUP_PICKUP_REWARD": 5
      }
    },
    "mdp_params": {
      "layout_name": "cramped_room",
      "rew_shaping_params": {
        "DISH_DISP_DISTANCE_REW": 0,
        "DISH_PICKUP_REWARD": 3,
        "PLACEMENT_IN_POT_REW": 3,
        "POT_DISTANCE_REW": 0,
        "SOUP_DISTANCE_REW": 0,
        "SOUP_PICKUP_REWARD": 5
      }
    },
    "multi_agent_params": {
      "bc_opt": false,
      "bc_schedule": [
        [
          0,
          0
        ],
        [
          Infinity,
          0
        ]
      ],
      "ficticious_self_play": false,
      "potential_constants": {
        "max_delivery_steps": 10,
        "max_pickup_steps": 20,
        "min_coeff": 0.7,
        "non_useful_counter_coeff": 0,
        "pot_onion_steps": 10,
        "pot_tomato_steps": 10,
        "useful_counter_coeff": 2
      },
      "potential_shaping_schedule": [
        [
          0,
          1.0
        ],
        [
          Infinity,
          0
        ]
      ],
      "reward_shaping_schedule": [
        [
          0,
          1.0
        ],
        [
          3000000.0,
          0
        ]
      ],
      "use_potential_shaping": false,
      "use_reward_shaping": false
    },
    "outer_shape": null
  },
  "evaluation_interval": 10,
  "gamma": 0.99,
  "grad_clip": 0.1,
  "kl_coeff": 0.2,
  "lambda": 0.98,
  "log_level": "ERROR",
  "lr": 5e-05,
  "lr_schedule": null,
  "multiagent": {
    "policies": {
      "ppo": [
        null,
        "Box(0.0, inf, (5, 4, 26), float32)",
        "Discrete(6)",
        {
          "model": {
            "custom_model": "MyPPOModel",
            "custom_model_config": {
              "CELL_SIZE": 256,
              "D2RL": false,
              "NUM_CONV_LAYERS": 3,
              "NUM_FILTERS": 25,
              "NUM_HIDDEN_LAYERS": 3,
              "SIZE_HIDDEN_LAYERS": 64,
              "use_lstm": false,
              "vf_share_layers": true
            }
          }
        }
      ]
    },
    "policies_to_train": [
      "ppo"
    ],
    "policy_mapping_fn": "<function gen_trainer_from_params.<locals>.select_policy at 0x7f874c3e04d0>"
  },
  "num_gpus": 0,
  "num_sgd_iter": 1,
  "num_workers": 0,
  "rollout_fragment_length": 400,
  "seed": 0,
  "sgd_minibatch_size": 800,
  "train_batch_size": 800,
  "vf_loss_coeff": 0.0001
}